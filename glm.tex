\section{Обобщенные линейные модели}


\subsection{Введение в ОЛМ}


Назначение обобщенных линейных моделей (ОЛМ) показать зависимость между наблюдаемой величиной, также называемой откликом $Y$ и зависимыми переменными, называемыми факторами $X$. Модель рассматривает наблюдения $Y_i$, как реализации случайной величины $Y$.


Как и в многих других методах машинного обучения стоит отдельно рассмотреть категориальные и вещественные факторы. Категориальные факторы принимают конечное, заранее определённое число значений, называемых, уровнями фактора. Примерами могут служить пол человека, марка или модель его автомобиля, город проживания, взят ли автомобиль в кредит и т.д. Вещественные факторы принимают числовые значения, например, мощность, стоимость автомобиля, стаж, возраст водителя, число водителей,прописанных в полисе и т.д.

Случайную величину Y будем представлять в виде суммы её математического ожидания $\mu$ и случайной величины $\varepsilon$
\[
	Y = \mu + \varepsilon
\]
В дальнейшем будет показано, что с помощью факторов предсказывается $\mu$, а это предсказание оценивается на основе распределения случайной величины $\varepsilon$.





\subsection{Предположения обобщенной линейной модели}


\begin{itemize}
	\item Элементы отклика $Y$ являются независимыми. При этом они относятся к семейству экспоненциально распределенных 
	\item Влияние объясняющих переменных на отклик является аддитивным, но только после некоторого преобразования,которое выражается \textit{функцией связи} 


\end{itemize}
		




\subsection{ОЛМ на практике}

Нашей конечной задачей является оценить ожидаемые риски с данного полиса по имеющимся данным. Для использования ОЛМ важно разделить риски следующим образом:

\subsubsection*{по виду риска}. А именно:
		\begin{itemize}
			\item Тотальная гибель автомобиля
			\item Угон
			\item ДТП Виновник
			\item ДТП Потерпевший
			\item Противоправные действия третих лиц
			\item Остальное
			
		\end{itemize}
		
		это очень важное действие, поскольку многие факторы сказываются на этих рисках совершенно по-разному. Например, можно утверждать, что водители с небольшим стажем имеют намного большие риски стать виновником в ДТП, но это нельзя говорить о, скажем, Противоправных действиях третих лиц или угонах. И наоборот, на такие риски большое флияние оказывает такой фактор, как наличие сигнализации, но на модель частоты виновника ДТП он не влияет.
	
\subsubsection*{разделение на частоту и тяжесть.} 
		для каждого полиса отдельно стоит оценивать ожидаемую частоту по данному риску и ожидаемую тяжесть (при условии, что происшествие произошло) по той же простой причине: зависимости частоты и тяжести имеют совершенно разную природу.
		
Для примера можно рассмотреть риск ДТП Потерпевший. 

Частота:

	\includegraphics[scale=0.5]{data/experiense/experiense_frequency}
Опытные водители реже становятся потерпевшими в ДТП. Достаточно предсказуемо.

Тяжесть:

	\includegraphics[scale=0.5]{data/experiense/experiense_severity}
Здесь мы наблюдаем обратную ситуацию. Тяжесть данного риска возрастает со стажем. Это объясняется следующим образом, водители с большим стажем являются более возрастными водителями, а значит они, вероятно водят более дорогой автомобиль. Это объясняет рост тяжести. Стоит отметить, что стаж сам по себе тоже влияет на тяжесть, так как опытные водители лучше реагиуют на нарушения правил других водителей.

	Но самыми наглядными примерами являются риски Тотальная гибель автомобиля и Угон. Тяжесть у этих рисков не зависят ни от чего, кроме страховой суммы, а вот про частоту этих рисков, разумеется, этого сказать нельзя. 

	Данные примеры показывают, что частота и тяжесть ДТП имеют совершенно различную природу, поэтому необходимо строить на них отдельные модели.

	Покажем правомерность такого разделения. Обозначим $N$ - случайная величина, число убытков для данного полиса, а $Z_1, Z_2, ... , Z_N$ - случайные величины, тяжести этих убытков. Здесь делается разумное предположение, что случайные величины $N, Z_1, Z_2, ... , Z_N$ являются независимыми, а $Z_1, Z_2, ... , Z_N$ одинакого распределёнными.Тогда суммарный ущерб для данного полиса составит 

$$ S = Z_1 + Z_2 + ... + Z_N $$

Тогда можно заметить, что

$$ E[S] = E[Z_1 + Z_2 + ... + Z_N] = E[E[Z_1 + Z_2 + ... + Z_N] | N] $$

$$ E[S] = E[E[Z_1 | N] + ... + E[Z_N | N]] = E[N E[Z]] $$

$$ E[S] = E[N]  E[Z] $$

Из сказанного следует, что мы можем отдельно моделировать частоту и тяжесть убытков, а затем просто перемножить их результаты для получения ожидаемого убытка. 


\subsection{Структура ОЛМ}

Структура ОЛМ может быть описана, как:
\[
	\mu_i = E[Y_i] = g^{-1}(\sum_{j}{X_{ij}} \beta_{j} + \xi_{i})		
\]

\[
	\varepsilon_i = Var[Y_i] = \frac{\phi V(\mu_i)}{\omega_i}
\]

где

\begin{itemize}
	\item $Y$ вектор наблюдений
	\item $g(x)$ функция связи - заданая обратимая функия, которая связывает отклик с линейной комбинацией признаков.
	\item $X$ - матрица плана, полученная из факторов
	\item $\beta$ - вектор параметров модели, которые будут оцениваться.
	\item $\xi$ - вектор известных смещений.
	\item $\phi$ - параметр дисперсии
	\item $V(x)$ - функция дисперсии
	\item $w$ - вектор весов, которые задают достоверность данных для каждого наблюдения.	
\end{itemize}

Линейная комбинация объясняющих переменных $\eta = X \beta$ называется \textit{систематической компонентой модели} или \textit{предиктором}, а сами элементы вектора $Y$ называются \textit{случайной компонентой модели}

Вектор откликов, матрица плана и смещения, основываются на данных. Функция связи $g(x)$, функция дисперсии $V(x)$ и параметр $\phi$ задаются исследователем.



\subsubsection{Функция связи}

Функция связи показывает взаимосвязь случайной и систематической компоненты модели. Выбирая функцию связи, мы можем менять вид влияния переменных на переменную отклика. Например, взяв $g(x)$ тождественной, мы получим модель, в которой каждый фактор оказывает аддитивное влияние на наблюдаемую переменную. 

\[
	\mu_i = E[Y_i] = \sum_{j}{X_{ij}} \beta_{j} + \xi_{i}
\]


Выбором $g(x)$ мы можем добиться так же и мультипликативного влияния. для  этого нужно взять $g(x) = ln(x)$ 
тогда получим:

$$ E[Y] = g^{-1}(X \beta) $$

$$ E[Y] = exp\{X \beta\} $$

$$ E[Y] = exp\{ \sum_{i = 1}^pX_i \beta_i \}$$

$$ E[Y] = \prod_{i = 1}^p exp\{ X_i \beta_i \}$$

Варьируя $\beta_i$, мы можем произвольно изменять $exp\{ X_i \beta_i \}$, а эта величина имеет мультипликативное влияние на $ E[Y_i] $. При тарификации КАСКО используется именно эта функция связи, поскольку мультипликативная зависимость легко интерпретируется, что позволяет добиться высокого качества модели. Модели с такой функцией связи называются \textit{мультипликативными}.

\subsubsection{Вектор известных смещений}
	Применяется, когда есть возможность учесть некоторые заранее известные влияния факторов. Например, при анализе количества убытков с помощью мультипликативной ОЛМ, в качестве вектора известных смещений может выступать $ln(e_i)$, где $e_i$ - продолжительность полиса. Действительно, ожидаемое количество убытков пропорционально продолжительности полиса и при подстановке $\xi_i = ln(e_i)$, мы получим
\[
	\mu_i = E[Y_i] = g^{-1}(\sum_{j}{X_{ij}} \beta_{j} + \xi_{i})
\]

\[
	\mu_i = E[Y_i] = g^{-1}(\sum_{j}{X_{ij}} \beta_{j} + ln(e_i))
\]

\[
	\mu_i = E[Y_i] = g^{-1}(\sum_{j}{X_{ij}} \beta_{j}) e_i
\]

Заметим, что при анализе частоты такого не происходит. 


Возможны и менее очевидные применения. Например, мы можем располагать точными данными, относительно того, насколько дороже обходится ремонт авто в том или ином регионе. Тогда в качестве известного смещения для модели тяжести можно взять логарифм от какой-либо средней меры ремонта.  Важно отметить, что это влияние не описывает полностью зависимость полностью модели тяжести от региона. Помимо упомянутого, может оказаться, что какие-то регионы, например, более склонны к тяжелым авариям.
	
В дальнейшем, мы применим вектор известных смещений для решения поставленной нами задачи с многоуровневыми факторами.

\subsection{Оценка параметров ОЛМ методом максимального правдоподобия} \label{beta_est}
	После того, как модель была задана своими параметрами $X, g(x), \xi, V(x), \phi$, а также дан вектор наблюдений $Y$, компоненты вектора $\beta$ оцениваются путём нахождения максимума правдоподобия. Другими словами, вектор $\beta$ мы подбираем так, чтобы вероятность получения наблюдаемых факторов была максимальной. Правдоподобие задаётся произведением наблюдения каждой переменной. Общепринятым считается подход замены функции правдоподобия на её логарифм. Это замена уместна, т.к. логарифм монотонно возрастает. Преимущество этого подхода заключается в том, что логарифм преобразует произведение вероятностей наблюдений в сумму, что упрощает вычисления.

При нахождении вектора $\beta$ максимизирующего правдоподобие на данных с небольшим числом наблюдений можно воспользоваться методами линейной алгебры. Но на практике приходится работать с большим объёмом данных и аналитические методы становяться неприменимы. Вместо этого исльпользуются численные методы, например, многомерный алгоритм Ньютона-Рафсона.


\subsection{Стандартные ОЛМ модели}

Как было указано выше, для анализа среднего убытка для заданного риска, полезно разбить этот риск на две составляющие: частоту убытков и их тяжесть, а затем просто перемножить. После этого стоит задуматься о предположениях для этих моделей. При анализе частоты убытка стандартной является мультипликативная модель с Пуассоновским распределением. Такая модель замечательна тем, что она даёт результаты инвариантные относительно изменения временного периода наблюдения. То есть при изменении длины рассматривомого промежутка скажем с 1 года до двух результаты не изменяться. Для некоторых других распределений (например, гамма) это свойство не выполняется.


Для модели тяжести стандартной является мультипликативная модель с гамма распределением. Эта модель удовлетворяет свойству инвариатности относительно изменения валюты. То есть при моделировании с валютой в рублях или в долларах, мы получим одинаковый результат. Такое свойство выполняется не для всех распределений, например, для Пуассоновского.





\subsection{Проблемы связанные с маленькими группами}

Мы покажем, почему все уровни любого фактора не должны содержать мало данных. Рассмотрим модели частот. Здесь же мы и поясним, что в данном случае означает мало. Предположим, что у нас имеется некоторый фактор $F$, у которого есть уровень $L$, которому удовлетворяет мало данных из статистической базы. А раз этот уровень содержит мало данных, то велика вероятность того, что в данных с уровнем $L$ фактора $F$  нет ни одного происшествия. Это особенно актуально для рисков с маленькими частотами, а именно угоны и Тотали. Для них частоты порядка 0.001. А поскольку частота ДТП будет предсказываться, как

$$ 
exp\{ \sum_{j=1}^p X_{ij} \beta_j   +   \xi_i \}
$$. 


для всех $i$. Тогда для всех наблюдений $i$, которые относятся к фактору $L$ будет следующая оценка

$$ 
0 = exp\{ \sum_{j=1}^p X_{ij} \beta_i   +   \xi_i \}
$$. 

пусть коэффицент $\beta_j$ соответствует уровню $L$ фактора $F$. Тогда можно сделать следующее наблюдение: 

\textbf{Утверждение}. Для любого вектора $\beta$ при уменьшении компоненты $\beta_j$, функция правдоподобия будет увеличиваться.

Действительно, при уменьшении компоненты $\beta_j$, правдоподобие на наблюдениях $i$ не относящихся к уровню $L$ не измениться т.к. по построению матрицы плана соотвествующий коэффицент $X_{ij}$ , будет 0, а значит выражение 
$$ 
exp\{ \sum_{j=1}^p X_{ip} \beta_p   +   \xi_i \}
$$
для таких $i$ не будет изменяться. при этом, для наблюдений $i$, относящихся к уровню $L$ соотвествующий коэффицент $X_{ij} = 1$. тогда выражение
$$ 
exp\{ \sum_{j=1}^p X_{ip} \beta_p   +   \xi_i \} =
$$
уменьшится, при уменьшении $\beta_j$.

Доказанное утверждение, означает, что в таком случае не существует оптимального вектора $\beta_j$. Нестрого говоря, для таких данных оптимальное значение $\beta_j = - \infty $. На практике, это приведёт к тому, что численный алгоритм, нахождения $\beta$ в какой-то момент остановиться и сделает $\beta_j$  большим отрицательным, что приводит к странным, искажённым результатам.

Данные рассуждения показывают, почему каждый уровень любого фактора должен содержать достаточно большое количество факторов. Разумеется, это не единственная проблема, поскольку неправильно оценивать влияние фактора по малому числу наблюдений, а данный пример вырожденный случай этой проблемы. Это затрагивает многоуровневые факторых, речь о которых пойдёт ниже.





