\section*{Обобщенные линейные модели}


\subsection*{Введение в ОЛМ}


Назначение обобщенных линейных моделей (ОЛМ) показать зависимость между наблюдаемой величиной, также называемой откликом $Y$ и зависимыми переменными, называемыми факторами $X$. Модель рассматривает наблюдения $Y_i$, как реализации случайной величины $Y$.


Случайную величину Y будем представлять в виде суммы её математического ожидания $\mu$ и случайной величины $\varepsilon$
\[
	Y = \mu + \varepsilon
\]
В дальнейшем будет показано, что с помощью факторов предсказывается $\mu$, а это предсказание оценивается на основе распределения случайной величины $\varepsilon$.


\newpage

\subsection*{Структура ОЛМ}

Структура ОЛМ может быть описана, как:
\[
	\mu_i = E[Y_i] = g^{-1}(\sum_{j}{X_{ij}} \beta_{j} + \xi_{i})		
\]

\[
	\varepsilon_i = Var[Y_i] = \frac{\phi V(\mu_i)}{\omega_i}
\]

где

\begin{itemize}
	\item $Y$ вектор наблюдений
	\item $g(x)$ функция связи - заданая обратимая функия, которая связывает отклик с линейной комбинацией признаков.
	\item $X$ - матрица плана, полученная из факторов
	\item $\beta$ - вектор параметров модели, которые будут оцениваться.
	\item $\xi$ - вектор известных смещений.
	\item $\phi$ - параметр дисперсии
	\item $V(x)$ - функция дисперсии
	\item $w$ - вектор весов, которые задают достоверность данных для каждого наблюдения.	
\end{itemize}

Вектор откликов, матрица плана и смещения, основываются на данных. Функция связи $g(x)$, функция дисперсии $V(x)$ и параметр $\phi$ задаются исследователем.





\subsection*{Предположения обобщенной линейной модели}


\begin{itemize}
	\item Элементы отклика $Y$ являются независимыми. При этом они относятся к семейству экспоненциально распределенных 
	\item Влияние объясняющих переменных на отклик является аддитивным, но только после некоторого преобразования,которое выражается \textit{функцией связи} 


\end{itemize}
		



\newpage

\subsection*{ОЛМ на практике}

Нашей конечной задачей является оценить ожидаемые риски с данного полиса по имеющимся данным. Для использования ОЛМ важно разделить риски следующим образом:

\subsubsection*{По виду риска} А именно:
		\begin{itemize}
			\item Тотальная гибель автомобиля
			\item Угон
			\item ДТП Виновник
			\item ДТП Потерпевший
			\item Противоправные действия третих лиц
			\item Остальное
			
		\end{itemize}
		
		Это очень важное действие, поскольку многие факторы сказываются на этих рисках совершенно по-разному. Например, можно утверждать, что водители с небольшим стажем имеют намного большие риски стать виновником в ДТП, но это нельзя говорить о, скажем, противоправных действиях третих лиц или угонах. И наоборот, на такие риски большое флияние оказывает такой фактор, как наличие сигнализации, но на модель частоты виновника ДТП он не влияет.
	
	
\newpage
	
\subsubsection*{Разделение на частоту и тяжесть} 
		Для каждого полиса отдельно стоит оценивать ожидаемую частоту по данному риску и ожидаемую тяжесть (при условии, что происшествие произошло) по той же простой причине: зависимости частоты и тяжести имеют совершенно разную природу.
		
Для примера можно рассмотреть риск ДТП Потерпевший. 

Частота:

	\includegraphics[scale=0.5]{data/experiense/experiense_frequency}
Опытные водители реже становятся потерпевшими в ДТП. Достаточно предсказуемо.

Тяжесть:

	\includegraphics[scale=0.5]{data/experiense/experiense_severity}
Здесь мы наблюдаем обратную ситуацию. Тяжесть данного риска возрастает со стажем. Это объясняется следующим образом, водители с большим стажем являются более возрастными водителями, а значит они, вероятно водят более дорогой автомобиль. Это объясняет рост тяжести. Стоит отметить, что стаж сам по себе тоже влияет на тяжесть, так как опытные водители лучше реагиуют на нарушения правил других водителей.

	Но самыми наглядными примерами являются риски Тотальная гибель автомобиля и Угон. Тяжесть у этих рисков не зависят ни от чего, кроме страховой суммы, а вот про частоту этих рисков, разумеется, этого сказать нельзя. 

	Данные примеры показывают, что частота и тяжесть ДТП имеют совершенно различную природу, поэтому необходимо строить на них отдельные модели.

	В работе была показана правомерность данного разделения.

\newpage


\subsection*{Стандартные ОЛМ модели}

Как было указано выше, для анализа среднего убытка для заданного риска, полезно разбить этот риск на две составляющие: частоту убытков и их тяжесть, а затем просто перемножить. После этого стоит задуматься о предположениях для этих моделей. При анализе частоты убытка стандартной является мультипликативная модель с Пуассоновским распределением. Такая модель замечательна тем, что она даёт результаты инвариантные относительно изменения временного периода наблюдения. То есть при изменении длины рассматривомого промежутка скажем с 1 года до двух результаты не изменяться. Для некоторых других распределений (например, гамма) это свойство не выполняется.


Для модели тяжести стандартной является мультипликативная модель с гамма распределением. Эта модель удовлетворяет свойству инвариатности относительно изменения валюты. То есть при моделировании с валютой в рублях или в долларах, мы получим одинаковый результат. Такое свойство выполняется не для всех распределений, например, для Пуассоновского.



\newpage


\subsection*{Проблемы связанные с маленькими группами}

Мы покажем, почему все уровни любого фактора не должны содержать мало данных. Рассмотрим модели частот. Здесь же мы и поясним, что в данном случае означает мало. Предположим, что у нас имеется некоторый фактор $F$, у которого есть уровень $L$, которому удовлетворяет мало данных из статистической базы. А раз этот уровень содержит мало данных, то велика вероятность того, что в данных с уровнем $L$ фактора $F$  нет ни одного происшествия. Это особенно актуально для рисков с маленькими частотами, а именно угоны и тотали. Для них частоты порядка 0.001. А поскольку частота ДТП будет предсказываться, как

$$ 
exp\{ \sum_{j=1}^p X_{ij} \beta_j   +   \xi_i \}
$$. 


для всех $i$. Тогда для всех наблюдений $i$, которые относятся к фактору $L$ будет следующая оценка

$$ 
0 = exp\{ \sum_{j=1}^p X_{ij} \beta_i   +   \xi_i \}
$$. 

пусть коэффицент $\beta_j$ соответствует уровню $L$ фактора $F$. Тогда можно сделать следующее наблюдение: 

\textbf{Утверждение}. Для любого вектора $\beta$ при уменьшении компоненты $\beta_j$, функция правдоподобия будет увеличиваться.

Действительно, при уменьшении компоненты $\beta_j$, правдоподобие на наблюдениях $i$ не относящихся к уровню $L$ не измениться т.к. по построению матрицы плана соотвествующий коэффицент $X_{ij}$ , будет 0, а значит выражение 
$$ 
exp\{ \sum_{j=1}^p X_{ip} \beta_p   +   \xi_i \}
$$
для таких $i$ не будет изменяться. при этом, для наблюдений $i$, относящихся к уровню $L$ соотвествующий коэффицент $X_{ij} = 1$. тогда выражение
$$ 
exp\{ \sum_{j=1}^p X_{ip} \beta_p   +   \xi_i \} =
$$
уменьшится, при уменьшении $\beta_j$.

Доказанное утверждение, означает, что в таком случае не существует оптимального вектора $\beta_j$. Нестрого говоря, для таких данных оптимальное значение $\beta_j = - \infty $. На практике, это приведёт к тому, что численный алгоритм, нахождения $\beta$ в какой-то момент остановиться и сделает $\beta_j$  большим отрицательным, что приводит к странным, искажённым результатам.

Данные рассуждения показывают, почему каждый уровень любого фактора должен содержать достаточно большое количество факторов. Разумеется, это не единственная проблема, поскольку неправильно оценивать влияние фактора по малому числу наблюдений, а данный пример вырожденный случай этой проблемы. Это затрагивает многоуровневые факторых, речь о которых пойдёт ниже.





