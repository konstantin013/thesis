
\subsection{Использование теории достоверности в многоуровневых факторах}

\subsubsection{Модель Бюльмана-Штрауба}

	Данная модель рассматривает частный случай нашей модели. А именно, в этой модели присутствует только один фактор, и он является многоуровневым. Здесь будут приведены важные результаты, которые будут перенесены на рассматриваемую нами модель.



	Рассмотрим многоуровневый фактор $F$ с уровнями $\{ 1, 2, ..., J\}$. Будем обозначать наблюдения рассматриваемой случайной величины, как $Y_{jt}$, где $j$ - уровень фактора $F$, $t$ - номер среди таких наблюдений. $\mu$ - среднее по всем наблюдениям:
	
$$
	\mu = \frac{\sum_{jt}w_{jt}Y_{jt}}{\sum_{jt}w_{jt}}
$$

Для каждого уровня $j \in \{1, ..., J\}$ посчитаем для него среднее:

$$
	\overline{Y}_j = \frac{\sum_{t}w_{jt}Y_{jt}}{\sum_{jt}w_{jt}}
$$

Здесь, в отличии от обычного фактора, метод максимального правдоподобия неприменим, т.к. каждый из коэффициентов $e^{\beta_j}$ будет рассчитываться по слишком малому количеству наблюдений.

Для каждого уровня $j$ будем делать разумное предсказание на реальное среднее наблюдаемой случайной величины. Здесь нужно найти некоторый компромисс между $\overline{Y}_j$ и $\mu$. Первый является нестабильным, поскольку посчитан на малых данных. Второй стабильный, но никак не отражает зависимости от уровня $j$.

Будем считать, что каждый уровень подвержен \textit{случайному эффекту} $U_j$. Для мультипликативной модели имеем:
$$
	E[Y_{jt} | U_j] = \mu U_j
$$
,где $E[U_j] = 1$

Для удобства сделаем замену $V_j = \mu U_j$. Тогда имеем:
$$
	E[Y_{jt} | V_j] = V_j
$$
,где $E[V_j] = \mu$

Здесь необходимо сделать предположения
\begin{itemize}
	\item $\forall j$ случайные векторы $(Y_{jt}, V_j)$ независимы
	\item $V_j$ одинаково распределены со средним $E[V_j] = \mu > 0$
	\item $\forall j$ все $Y_{jt}$ при условии $V_j$ независимы со средним $E[Y_{jt} | V_j] = V_j$
\end{itemize}


Задумаемся о том, как наилучшим образом оценить влияние каждого $V_j$.
Назовём \textit{достоверной оценкой} случайного эффекта $V$ линейную функцию $\widehat{V}$ наблюдений $Y$, которая минимизирует среднюю квадратичную ошибку

$$
E[(h(Y) - V) ^ 2]
$$

среди всех линейных функций $h(Y)$.

В работе \cite{Su80} было установлено существование и единственность достоверной оценки.
Следующая теорема показывает, как достоверная оценка может быть найдена.

%\begin{theorem}
%	достоверная оценка может быть найдена как
%\end{theorem}

\textbf{Теорема} (Бюльмана-Штрауба) \textit{Достоверная оценка для $V_j$ может быть найдена как
$$
\widehat{V}_j = z_j \overline{Y}_j + (1 - z_j) \mu
$$
где 
$$
z_j = \frac{w_j}{w_j + \sigma^2/\tau^2}
$$
}




\subsubsection{Достоверные оценки в мультипликативных моделях}

Покажем, как применить полученные результаты в мультипликативных моделях с одним многоуровневым фактором. 

Обозначим $R$ - количество обычных факторов. Эти факторы в совокупности образуют множество тарифных ячеек. Рассмотим тарифную ячейку $i$. Для данной тарифной ячейки обычные факторы образуют коффициенты $\gamma_1^i, \gamma_2^i, ... , \gamma_R^i, $. Здесь мы переобозначили $e^{\beta_r^i} = \gamma_r^i$, использовавшееся ранее. Обозначения для многоуовневого фактора мы сохраним из предыдущего раздела. Тогда мы получаем следующую модель:
$$
E[Y_{ijt} | U_j] = \mu \gamma_1^i ... \gamma_R^i U_j
$$
Здесь $\mu$ - среднее для базовой ячейки, т.е. для которой $\gamma_r^i = 1, r = 1, ... ,R$.
Для упрощения записи введём
$$
\gamma_1^i ... \gamma_R^i = \gamma_i
$$
Как и в предыдущем разделе $V_j = \mu U_j$. Тогда модель можно переписать как:
$$
E[Y_{ijt} | U_j] = \gamma_i V_j
$$

Перепишем предположения сделанные в предыдущем разделе для данной модели.

\begin{itemize}
	\item $\forall j$ случайные векторы $(Y_{ijt}, V_j)$ независимы
	\item $V_j$ одинаково распределены со средним $E[V_j] = \mu > 0$
	\item $\forall j$ все $Y_{jt}$ при условии $V_j$ независимы со средним $E[Y_{jt} | V_j] = V_j$
\end{itemize}

Теперь изменим наблюдаемые переменные, чтобы получть модель Бюльмана-Штрауба:
$$
\widetilde{Y}_{ijt} = \frac{Y_{ijt}}{\gamma_i}, \qquad
\widetilde{w}_{ijt} = w_{ijt} \gamma_i^{2 - p}
$$
Заметим, что теперь
$$
E[\widetilde{Y}_{ijt} | V_j] = V_j
$$

То есть мы свели нашу модель к модели Бюльмана-Штрауба. А к ней можно применить теорему Бюльмана-Штрауба. Тогда мы получим следующее:


\textbf{Утверждение} \textit{Достоверная оценка для $V_j$ может быть найдена как
$$
\widehat{V}_j = z_j \overline{Y}_j + (1 - z_j) \mu
$$
где 
$$
z_j = \frac{w_j}{w_j + \sigma^2/\tau^2}
$$
}


\subsubsection{backfitting алгоритм}

Как только мы имеем коэффиценты для нашей модели, мы можем оценить $widehat{U}_j$. А после этого, используя эти оценки для смещений $\widehat{U}_j$, как вектор известных смещений $\xi$, мы можем улучшить модель, заново пересчитав коффициенты. затем опять пересчитать оценки для $widehat{U}_j$ уже на новых коэффициентах и т.д. Эти несложные рассуждения приводят нас к backfitting алгоритму. Запишем его в итеративном виде.
\begin{enumerate}
	\item[0] Первоначально положим $\widehat{U}_j = 1, \forall j$ 
	\item Используя имеющиеся $\widehat{U}_j$ как вектор известных смещений $\xi$, оцениваем коэффициенты $\gamma_r^i$ обычным для мультипликативной модели образом. 
	\item Пересчитываем $\widehat{U}_j$ согласно формуле такой-то.
	\item Возвращаемся к шагу 0.
\end{enumerate}
Повторяем шаги 1-4 до сходимости.

Заметим, что использование начального приближения $\widehat{U}_j = 1, \forall j$ на шаге 0, равносильно тому, что данный многоуровневый фактор просто не включается в модель.